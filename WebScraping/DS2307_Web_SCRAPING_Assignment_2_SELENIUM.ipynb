{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "242e6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You\n",
    "#have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "#This task will be done in following steps:\n",
    "#1. First get the webpage https://www.shine.com/\n",
    "#2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "#3. Then click the searchbutton.\n",
    "#4. Then scrape the data for the first 10 jobs results you get.\n",
    "#5. Finally create a dataframe of the scraped data.\n",
    "#Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10a3e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2.0.4)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f84d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impoting all the necessary libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5675e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7b3f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Opening the shine page on automated chrome browser:\n",
    "driver.get(\"https://www.shine.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f6e9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field:\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ec6a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31ef633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Clicking the Search Button\n",
    "Search=driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ce2f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Scraping the data for the first 10 jobs results you get.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "536285b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e36a118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "72e982e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Coordinator (Data Analyst)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>ashutosh sabhashankar chaturvedi hi...</td>\n",
       "      <td>7 to 12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst Urgent Recruiment</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apply Now a Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apply Now Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needed for Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgently need a Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title        Location  \\\n",
       "0  Project Coordinator (Data Analyst)       Bangalore   \n",
       "1          Data Analyst - Java/Python       Bangalore   \n",
       "2             Hiring For Data Analyst  Bangalore\\n+14   \n",
       "3                 Senior Data Analyst       Bangalore   \n",
       "4                        Data Analyst   Bangalore\\n+9   \n",
       "5      Data Analyst Urgent Recruiment  Bangalore\\n+14   \n",
       "6            Apply Now a Data Analyst       Bangalore   \n",
       "7              Apply Now Data Analyst       Bangalore   \n",
       "8             Needed for Data Analyst       Bangalore   \n",
       "9        Urgently need a Data Analyst       Bangalore   \n",
       "\n",
       "                             Company_name   Experience  \n",
       "0                     futures and careers   2 to 4 Yrs  \n",
       "1  boyen haddin consulting and technol...   3 to 6 Yrs  \n",
       "2                kavya staffing solutions   0 to 4 Yrs  \n",
       "3           ara resources private limited   2 to 5 Yrs  \n",
       "4  ashutosh sabhashankar chaturvedi hi...  7 to 12 Yrs  \n",
       "5                       divya interprises   0 to 4 Yrs  \n",
       "6       deuglo infosystem private limited   1 to 2 Yrs  \n",
       "7       deuglo infosystem private limited   1 to 2 Yrs  \n",
       "8       deuglo infosystem private limited   1 to 2 Yrs  \n",
       "9       deuglo infosystem private limited   1 to 2 Yrs  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of the scraped data\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10399f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2:Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in‚ÄúBangalore‚Äù location. You\n",
    "#have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc0e64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6fe8d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Opening the shine page on automated chrome browser:\n",
    "driver.get(\"https://www.shine.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fbf94cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Enter ‚ÄúData Scientist‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBanglore‚Äù in ‚Äúenter the location‚Äù field:\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0d0df983",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c024f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Clicking the Search Button\n",
    "Search=driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "adee3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Scraping the data for the first 10 jobs results you get.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29b1b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fbfbf249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6343841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Urgent Recruitment</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Required for Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgently need Data Scientist</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data scientist Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>seven geomax consulting private lim...</td>\n",
       "      <td>6 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>employberry consultants hiring for ...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>niharika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Needed for the post Data Scientist</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title        Location  \\\n",
       "0           Hiring For Data Scientist  Bangalore\\n+17   \n",
       "1           Hiring For Data Scientist  Bangalore\\n+17   \n",
       "2                      Data Scientist       Bangalore   \n",
       "3   Data Scientist Urgent Recruitment  Bangalore\\n+14   \n",
       "4         Required for Data Scientist       Bangalore   \n",
       "5        Urgently need Data Scientist   Bangalore\\n+8   \n",
       "6            Data scientist Bangalore       Bangalore   \n",
       "7                      Data Scientist       Bangalore   \n",
       "8           Hiring For Data Scientist  Bangalore\\n+15   \n",
       "9  Needed for the post Data Scientist   Bangalore\\n+8   \n",
       "\n",
       "                             Company_name   Experience  \n",
       "0                kavya staffing solutions   0 to 4 Yrs  \n",
       "1                kavya staffing solutions   0 to 4 Yrs  \n",
       "2                     skyleaf consultants  5 to 10 Yrs  \n",
       "3                       divya interprises   0 to 4 Yrs  \n",
       "4       deuglo infosystem private limited   4 to 6 Yrs  \n",
       "5       deuglo infosystem private limited   4 to 6 Yrs  \n",
       "6  seven geomax consulting private lim...   6 to 9 Yrs  \n",
       "7  employberry consultants hiring for ...   3 to 6 Yrs  \n",
       "8                    niharika enterprises   0 to 4 Yrs  \n",
       "9       deuglo infosystem private limited   4 to 6 Yrs  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of the scraped data\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e238035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "#You have to use the location and salary filter.\n",
    "#You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "#You have to scrape the job-title, job-location, company name, experience required.\n",
    "#The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e2b7e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de910828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Opening the shine page on automated chrome browser:\n",
    "driver.get(\"https://www.shine.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f3223dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Enter ‚ÄúData Scientist‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúDelhi/NCR‚Äù in ‚Äúenter the location‚Äù field:\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e48d191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "814d0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Clicking the Search Button\n",
    "Search=driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "23ab5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "Salary=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div/ul/li[3]/button')\n",
    "Salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c0d02394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salary filter\n",
    "salary=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label')\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e7efbd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salary filter\n",
    "showresults=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]')\n",
    "showresults.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "53e0c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Scraping the data for the first 10 jobs results you get.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "adcbdffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "44675974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "50690c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>pro career ignition hr consultancy ...</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Modeling Analyst</td>\n",
       "      <td>Noida</td>\n",
       "      <td>ntt global networks</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Risk Analyst-QE</td>\n",
       "      <td>Noida</td>\n",
       "      <td>ntt global networks</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Risk Analyst,QE</td>\n",
       "      <td>Noida</td>\n",
       "      <td>ntt global networks</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title   Location  \\\n",
       "0                                Data Scientist  Delhi\\n+6   \n",
       "1                                Data Scientist      Delhi   \n",
       "2                                Data Scientist  Delhi\\n+6   \n",
       "3                                Data Scientist   Gurugram   \n",
       "4                                Data Scientist  Delhi\\n+4   \n",
       "5  for _GCP Data Engineer/Lead/Architect- Delhi      Delhi   \n",
       "6  for _GCP Data Engineer/Lead/Architect- Delhi      Delhi   \n",
       "7                              Modeling Analyst      Noida   \n",
       "8                               Risk Analyst-QE      Noida   \n",
       "9                               Risk Analyst,QE      Noida   \n",
       "\n",
       "                             Company_name  Experience  \n",
       "0                         quiscon biotech  0 to 3 Yrs  \n",
       "1                     skyleaf consultants  3 to 6 Yrs  \n",
       "2                         quiscon biotech   0 to 1 Yr  \n",
       "3  pro career ignition hr consultancy ...  0 to 2 Yrs  \n",
       "4           acme services private limited  3 to 5 Yrs  \n",
       "5                   nina s hr consultancy  2 to 3 Yrs  \n",
       "6                   nina s hr consultancy  2 to 3 Yrs  \n",
       "7                     ntt global networks  1 to 2 Yrs  \n",
       "8                     ntt global networks  1 to 2 Yrs  \n",
       "9                     ntt global networks  2 to 6 Yrs  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of the scraped data\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "09360bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#6. Brand\n",
    "#7. ProductDescription\n",
    "#8. Price\n",
    "#The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "cfcd180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "fa535cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Opening the flipkart page on automated chrome browser:\n",
    "driver.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "3333e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "845dd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "707a0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "985197c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    p_desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    price =driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    discount=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] \n",
    "    \n",
    "    \n",
    "    for t in discount:\n",
    "        Discount.append(t.text)\n",
    "    Discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e30cb93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(B_name[:100]),len(Price[:100]),len(P_desc[:100]),len(Discount[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8de6346a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Price</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>‚Çπ899</td>\n",
       "      <td>UV Protection, Polarized Over-sized Sunglasses...</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>‚Çπ379</td>\n",
       "      <td>Riding Glasses, UV Protection Clubmaster, Wayf...</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>‚Çπ204</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>‚Çπ239</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>‚Çπ179</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BKGE</td>\n",
       "      <td>‚Çπ197</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>‚Çπ335</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>‚Çπ965</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SmartGlass</td>\n",
       "      <td>‚Çπ429</td>\n",
       "      <td>UV Protection Aviator Sunglasses (62)</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>‚Çπ379</td>\n",
       "      <td>UV Protection Spectacle Sunglasses (Free Size)</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name Product Price  \\\n",
       "0    VINCENT CHASE          ‚Çπ899   \n",
       "1     Singco India          ‚Çπ379   \n",
       "2             SRPM          ‚Çπ204   \n",
       "3           PIRASO          ‚Çπ239   \n",
       "4        Elligator          ‚Çπ179   \n",
       "..             ...           ...   \n",
       "95            BKGE          ‚Çπ197   \n",
       "96  ROZZETTA CRAFT          ‚Çπ335   \n",
       "97   VINCENT CHASE          ‚Çπ965   \n",
       "98      SmartGlass          ‚Çπ429   \n",
       "99          PIRASO          ‚Çπ379   \n",
       "\n",
       "                                  Product Description Discount  \n",
       "0   UV Protection, Polarized Over-sized Sunglasses...  55% off  \n",
       "1   Riding Glasses, UV Protection Clubmaster, Wayf...  81% off  \n",
       "2              UV Protection Wayfarer Sunglasses (50)  84% off  \n",
       "3            UV Protection Clubmaster Sunglasses (54)  85% off  \n",
       "4   UV Protection Cat-eye, Retro Square, Oval, Rou...  70% off  \n",
       "..                                                ...      ...  \n",
       "95         UV Protection Retro Square Sunglasses (54)  85% off  \n",
       "96  by Lenskart Polarized, UV Protection Round Sun...  74% off  \n",
       "97  by Lenskart Polarized, UV Protection Cat-eye S...  77% off  \n",
       "98              UV Protection Aviator Sunglasses (62)  87% off  \n",
       "99     UV Protection Spectacle Sunglasses (Free Size)  25% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of the scraped data\n",
    "df=pd.DataFrame({'Brand Name':B_name[:100],'Product Price':Price[:100],'Product Description':P_desc[:100],'Discount':Discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f869aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "#https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "9ee01952",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "13ea4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page on automated chrome browser:\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "b0265b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Reviewsumm=[]\n",
    "Fullreview=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d7697d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    rating=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    reviewsumm=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    fullreview =driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    \n",
    "    for j  in rating:\n",
    "        Rating.append(j.text)\n",
    "    Rating[:100]    \n",
    "    \n",
    "    \n",
    "    for k in reviewsumm:\n",
    "        Reviewsumm.append(k.text)\n",
    "    Reviewsumm[:100] \n",
    "    \n",
    "    \n",
    "    for l in fullreview:\n",
    "        Fullreview.append(l.text)\n",
    "    Fullreview[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "90088b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Reviewsumm),len(Fullreview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f1dec25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>ReviewSummary</th>\n",
       "      <th>FullReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>V Good all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect Product!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Superüî• and good performance üëå‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Purple is best</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating        ReviewSummary  \\\n",
       "0       5       Classy product   \n",
       "1       5       Classy product   \n",
       "2       5             Terrific   \n",
       "3       5            Wonderful   \n",
       "4       5     Perfect product!   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5  Best in the market!   \n",
       "97      5            Just wow!   \n",
       "98      5            Fabulous!   \n",
       "99      5        Great product   \n",
       "\n",
       "                                           FullReview  \n",
       "0                                        Photos super  \n",
       "1   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "2                                      Very very good  \n",
       "3                              This is amazing at all  \n",
       "4                                          V Good all  \n",
       "..                                                ...  \n",
       "95  Feeling awesome after getting the delivery of ...  \n",
       "96                                        Good Camera  \n",
       "97                                  Perfect Product!!  \n",
       "98                    Superüî• and good performance üëå‚ù§Ô∏è  \n",
       "99                                     Purple is best  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of the scraped data\n",
    "df=pd.DataFrame({'Rating':Rating,'ReviewSummary':Reviewsumm,'FullReview':Fullreview})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "b07c0879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6: Scrape data for first 100 sneakers you find whenyou visit flipkart.com and search for ‚Äúsneakers‚Äù in the search field.\n",
    "#You have to scrape 3 attributes of each sneaker:\n",
    "#1. Brand\n",
    "#2. ProductDescription\n",
    "#3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "228ed139",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e0e30e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page on automated chrome browser:\n",
    "driver.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c252e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0cf72ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "7e77218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "P_desc=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "ada99a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    price =driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    p_desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "   \n",
    "   \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e2215d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(B_name[:100]),len(P_desc[:100]),len(Price[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c64f4df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Modern Trendy Sneakers boot Sneakers Sneakers ...</td>\n",
       "      <td>‚Çπ449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFR</td>\n",
       "      <td>Exclusive Affordable Collection of Trendy &amp; St...</td>\n",
       "      <td>‚Çπ349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>‚Çπ398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Asics</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ1,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Free Kicks</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>UP Sneakers For Men</td>\n",
       "      <td>‚Çπ519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand Name                                Product Description  \\\n",
       "0     Magnolia  Modern Trendy Sneakers boot Sneakers Sneakers ...   \n",
       "1          SFR  Exclusive Affordable Collection of Trendy & St...   \n",
       "2       BRUTON               Modern Trendy Shoes Sneakers For Men   \n",
       "3     Nobelite                                   Sneakers For Men   \n",
       "4         aadi  Synthetic Leather |Lightweight|Comfort|Summer|...   \n",
       "..         ...                                                ...   \n",
       "95       Asics                                   Sneakers For Men   \n",
       "96    RapidBox                                   Sneakers For Men   \n",
       "97    Magnolia                                   Sneakers For Men   \n",
       "98  Free Kicks                                   Sneakers For Men   \n",
       "99       Sparx                                UP Sneakers For Men   \n",
       "\n",
       "   Product Price  \n",
       "0           ‚Çπ449  \n",
       "1           ‚Çπ349  \n",
       "2           ‚Çπ379  \n",
       "3           ‚Çπ299  \n",
       "4           ‚Çπ398  \n",
       "..           ...  \n",
       "95        ‚Çπ1,699  \n",
       "96          ‚Çπ750  \n",
       "97          ‚Çπ499  \n",
       "98          ‚Çπ599  \n",
       "99          ‚Çπ519  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of the scraped data\n",
    "df=pd.DataFrame({'Brand Name':B_name[:100],'Product Description':P_desc[:100],'Product Price':Price[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba005688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
