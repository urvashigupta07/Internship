{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87cb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "#A) Rank B) Name C) Artist D) Upload date E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "901fe2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12abcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the wikipedia page on automated chrome browser:\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5cc4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for scraping data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd5c02c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Rank\n",
    "Rank=[]\n",
    "#rank = driver.find_elements(By.XPATH,'//td[@align=\"center\"]')[:15]\n",
    "rank = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')[:30]\n",
    "#                            song = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/h3')\n",
    "for i in rank:       \n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)   \n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02e4c48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " \"LooLoo Kids - Nursery Rhymes and Children's Songs\",\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'ChuChu TV Nursery Rhymes & Kids Songs',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'officialpsy',\n",
       " 'Get Movies',\n",
       " 'Ultra Records',\n",
       " 'Crazy Frog',\n",
       " 'Maroon 5',\n",
       " 'OneRepublic',\n",
       " 'Katy Perry',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Shakira',\n",
       " 'Justin Bieber',\n",
       " 'Jingle Toons',\n",
       " 'Ed Sheeran',\n",
       " 'Katy Perry',\n",
       " 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs',\n",
       " 'Ed Sheeran',\n",
       " 'Alan Walker',\n",
       " 'Passenger',\n",
       " 'Maroon 5',\n",
       " 'Major Lazer Official',\n",
       " 'Enrique Iglesias']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name=[]\n",
    "name = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')[:30]\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9a2a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " \"LooLoo Kids - Nursery Rhymes and Children's Songs\",\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'ChuChu TV Nursery Rhymes & Kids Songs',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'officialpsy',\n",
       " 'Get Movies',\n",
       " 'Ultra Records',\n",
       " 'Crazy Frog',\n",
       " 'Maroon 5',\n",
       " 'OneRepublic',\n",
       " 'Katy Perry',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Shakira',\n",
       " 'Justin Bieber',\n",
       " 'Jingle Toons',\n",
       " 'Ed Sheeran',\n",
       " 'Katy Perry',\n",
       " 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs',\n",
       " 'Ed Sheeran',\n",
       " 'Alan Walker',\n",
       " 'Passenger',\n",
       " 'Maroon 5',\n",
       " 'Major Lazer Official',\n",
       " 'Enrique Iglesias']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Artist\n",
    "Artist=[]\n",
    "artist = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')[:30]\n",
    "for i in artist:\n",
    "    if i.text is None :\n",
    "        Artist.append(\"--\") \n",
    "    else:\n",
    "        Artist.append(i.text)        \n",
    "Artist       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4add182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'May 2, 2018',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'May 24, 2018',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'June 16, 2009',\n",
       " 'January 14, 2015',\n",
       " 'May 31, 2013',\n",
       " 'September 5, 2013',\n",
       " 'June 25, 2018',\n",
       " 'June 4, 2010',\n",
       " 'October 22, 2015',\n",
       " 'June 14, 2018',\n",
       " 'October 7, 2014',\n",
       " 'February 20, 2014',\n",
       " 'January 26, 2018',\n",
       " 'November 9, 2017',\n",
       " 'December 3, 2015',\n",
       " 'July 25, 2012',\n",
       " 'May 31, 2018',\n",
       " 'March 22, 2015',\n",
       " 'April 11, 2014']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Upload_date\n",
    "Upload_date = []\n",
    "date = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')[:30]\n",
    "for i in date:       \n",
    "    if i.text is None :\n",
    "        Upload_date.append(\"--\") \n",
    "    else:\n",
    "        Upload_date.append(i.text)   \n",
    "Upload_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98afe41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.36 billions',\n",
       " '8.26 billions',\n",
       " '6.80 billions',\n",
       " '6.41 billions',\n",
       " '6.08 billions',\n",
       " '6.03 billions',\n",
       " '5.56 billions',\n",
       " '5.48 billions',\n",
       " '5.03 billions',\n",
       " '4.97 billions',\n",
       " '4.90 billions',\n",
       " '4.56 billions',\n",
       " '4.44 billions',\n",
       " '4.06 billions',\n",
       " '3.93 billions',\n",
       " '3.87 billions',\n",
       " '3.87 billions',\n",
       " '3.78 billions',\n",
       " '3.73 billions',\n",
       " '3.71 billions',\n",
       " '3.69 billions',\n",
       " '3.66 billions',\n",
       " '3.59 billions',\n",
       " '3.55 billions',\n",
       " '3.54 billions',\n",
       " '3.51 billions',\n",
       " '3.51 billions',\n",
       " '3.48 billions',\n",
       " '3.46 billions',\n",
       " '3.45 billions']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Views\n",
    "Views = []\n",
    "view = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')[:30]\n",
    "for i in view:       \n",
    "        if i.text is None:\n",
    "            Views.append(\"--\")\n",
    "        else:\n",
    "            Views.append(i.text+\" billions\")\n",
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "613aa1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.36 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.26 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.80 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.41 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.08 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.03 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.56 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.48 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.03 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.97 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.90 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.56 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.44 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.06 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.93 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.87 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.87 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.78 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.73 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.71 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.69 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.66 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.59 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.55 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.54 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.51 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.51 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.48 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.46 billions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.45 billions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                               Name  \\\n",
       "0    1.        Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "1    2.                                         Luis Fonsi   \n",
       "2    3.  LooLoo Kids - Nursery Rhymes and Children's Songs   \n",
       "3    4.                         Cocomelon - Nursery Rhymes   \n",
       "4    5.                                         Ed Sheeran   \n",
       "5    6.                                        Wiz Khalifa   \n",
       "6    7.                         Cocomelon - Nursery Rhymes   \n",
       "7    8.              ChuChu TV Nursery Rhymes & Kids Songs   \n",
       "8    9.                                        Mark Ronson   \n",
       "9   10.                                        Miroshka TV   \n",
       "10  11.                                        officialpsy   \n",
       "11  12.                                         Get Movies   \n",
       "12  13.                                      Ultra Records   \n",
       "13  14.                                         Crazy Frog   \n",
       "14  15.                                           Maroon 5   \n",
       "15  16.                                        OneRepublic   \n",
       "16  17.                                         Katy Perry   \n",
       "17  18.                         Cocomelon - Nursery Rhymes   \n",
       "18  19.                                            Shakira   \n",
       "19  20.                                      Justin Bieber   \n",
       "20  21.                                       Jingle Toons   \n",
       "21  22.                                         Ed Sheeran   \n",
       "22  23.                                         Katy Perry   \n",
       "23  24.      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   \n",
       "24  25.                                         Ed Sheeran   \n",
       "25  26.                                        Alan Walker   \n",
       "26  27.                                          Passenger   \n",
       "27  28.                                           Maroon 5   \n",
       "28  29.                               Major Lazer Official   \n",
       "29  30.                                   Enrique Iglesias   \n",
       "\n",
       "                                               Artist        Upload_date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                      Justin Bieber   October 22, 2015   \n",
       "20                                       Jingle Toons      June 14, 2018   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22                                         Katy Perry  February 20, 2014   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                        Alan Walker   December 3, 2015   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                           Maroon 5       May 31, 2018   \n",
       "28                               Major Lazer Official     March 22, 2015   \n",
       "29                                   Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "             Views  \n",
       "0   13.36 billions  \n",
       "1    8.26 billions  \n",
       "2    6.80 billions  \n",
       "3    6.41 billions  \n",
       "4    6.08 billions  \n",
       "5    6.03 billions  \n",
       "6    5.56 billions  \n",
       "7    5.48 billions  \n",
       "8    5.03 billions  \n",
       "9    4.97 billions  \n",
       "10   4.90 billions  \n",
       "11   4.56 billions  \n",
       "12   4.44 billions  \n",
       "13   4.06 billions  \n",
       "14   3.93 billions  \n",
       "15   3.87 billions  \n",
       "16   3.87 billions  \n",
       "17   3.78 billions  \n",
       "18   3.73 billions  \n",
       "19   3.71 billions  \n",
       "20   3.69 billions  \n",
       "21   3.66 billions  \n",
       "22   3.59 billions  \n",
       "23   3.55 billions  \n",
       "24   3.54 billions  \n",
       "25   3.51 billions  \n",
       "26   3.51 billions  \n",
       "27   3.48 billions  \n",
       "28   3.46 billions  \n",
       "29   3.45 billions  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Rank\":Rank,\"Name\":Name,\"Artist\":Artist,\"Upload_date\":Upload_date,\"Views\":Views})\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b20c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv. Url = https://www.bcci.tv/.You need to find following details: \n",
    "#A) Match title (I.e. 1 ODI) B) Series C) Place D) Date E) Time  Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a2c90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "640b05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the bcci page on automated chrome browser:\n",
    "driver.get(\"https://www.bcci.tv/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ad37bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the options\n",
    "#options=driver.find_element(By.XPATH,'//div[@class=\"navigation__drop-down drop-down drop-down--reveal-on-hover\"]')\n",
    "options=driver.find_element(By.XPATH,\"//*[contains(text(), 'INTERNATIONAL')]\")\n",
    "options.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a1cf959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for scraping data\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "# scraping match title\n",
    "series = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "\n",
    "for i in series:       \n",
    "    if i.text is None :\n",
    "        Series.append(\"--\") \n",
    "    else:\n",
    "        Series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f51370e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " '19TH ASIAN GAMES HANGZHOU 2022',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " 'ICC MENS WORLD CUP 2023 WARM-UP MATCHES',\n",
       " '19TH ASIAN GAMES HANGZHOU 2022',\n",
       " 'ICC MENS WORLD CUP 2023 WARM-UP MATCHES',\n",
       " 'ICC MENS WORLD CUP 2023',\n",
       " 'ICC MENS WORLD CUP 2023']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de4471ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st ODI -',\n",
       " 'Semi Final 1 -',\n",
       " '2nd ODI -',\n",
       " '3rd ODI -',\n",
       " '1st ODI -',\n",
       " 'Quarter Final 1 -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -',\n",
       " '2nd ODI -']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matchOrderText ng-binding ng-scope\n",
    "title = driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "\n",
    "for i in title:       \n",
    "    if i.text is None :\n",
    "        Match_title.append(\"--\") \n",
    "    else:\n",
    "        Match_title.append(i.text)\n",
    "Match_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799c3f2",
   "metadata": {},
   "source": [
    "place = driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "\n",
    "for i in place:       \n",
    "    if i.text is None :\n",
    "        Place.append(\"--\") \n",
    "    else:\n",
    "        Place.append(i.text) \n",
    "Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b465bab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st ODI -',\n",
       " 'Semi Final 1 -',\n",
       " '2nd ODI -',\n",
       " '3rd ODI -',\n",
       " '1st ODI -',\n",
       " 'Quarter Final 1 -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -',\n",
       " '2nd ODI -']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Match_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "816f9ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22 SEP 2023',\n",
       " '24 SEP 2023',\n",
       " '24 SEP 2023',\n",
       " '27 SEP 2023',\n",
       " '30 SEP 2023',\n",
       " '3 OCT 2023',\n",
       " '3 OCT 2023',\n",
       " '8 OCT 2023',\n",
       " '11 OCT 2023']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Date\n",
    "date = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date:       \n",
    "    if i.text is None :\n",
    "        Date.append(\"--\") \n",
    "    else:\n",
    "        Date.append(i.text)\n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33030227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:30 PM IST',\n",
       " '6:30 AM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '2:00 PM IST',\n",
       " '6:30 AM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST',\n",
       " '2:00 PM IST']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time=[]\n",
    "time = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time:       \n",
    "    if i.text is None :\n",
    "        Time.append(\"--\") \n",
    "    else:\n",
    "        Time.append(i.text)\n",
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88c4989e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Punjab Cricket Association IS Bindra Stadium,',\n",
       " 'Pingfeng Cricket Field,',\n",
       " 'Holkar Cricket Stadium,',\n",
       " 'Saurashtra Cricket Association Stadium,',\n",
       " 'Barsapara Cricket Stadium,',\n",
       " 'Pingfeng Cricket Field,',\n",
       " 'Greenfield International Stadium,',\n",
       " 'MA Chidambaram Stadium,',\n",
       " 'Arun Jaitley Stadium,']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Place=[]\n",
    "place = driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in place:       \n",
    "    if i.text is None :\n",
    "        Place.append(\"--\") \n",
    "    else:\n",
    "        Place.append(i.text)  \n",
    "Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e63aee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semi Final 1 -</td>\n",
       "      <td>19TH ASIAN GAMES HANGZHOU 2022</td>\n",
       "      <td>Pingfeng Cricket Field,</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>30 SEP 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quarter Final 1 -</td>\n",
       "      <td>19TH ASIAN GAMES HANGZHOU 2022</td>\n",
       "      <td>Pingfeng Cricket Field,</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>Greenfield International Stadium,</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>MA Chidambaram Stadium,</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>11 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Match_title                                   Series  \\\n",
       "0          1st ODI -          AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "1     Semi Final 1 -           19TH ASIAN GAMES HANGZHOU 2022   \n",
       "2          2nd ODI -          AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "3          3rd ODI -          AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "4          1st ODI -  ICC MENS WORLD CUP 2023 WARM-UP MATCHES   \n",
       "5  Quarter Final 1 -           19TH ASIAN GAMES HANGZHOU 2022   \n",
       "6          2nd ODI -  ICC MENS WORLD CUP 2023 WARM-UP MATCHES   \n",
       "7          1st ODI -                  ICC MENS WORLD CUP 2023   \n",
       "8          2nd ODI -                  ICC MENS WORLD CUP 2023   \n",
       "\n",
       "                                           Place         Date         Time  \n",
       "0  Punjab Cricket Association IS Bindra Stadium,  22 SEP 2023  1:30 PM IST  \n",
       "1                        Pingfeng Cricket Field,  24 SEP 2023  6:30 AM IST  \n",
       "2                        Holkar Cricket Stadium,  24 SEP 2023  1:30 PM IST  \n",
       "3        Saurashtra Cricket Association Stadium,  27 SEP 2023  1:30 PM IST  \n",
       "4                     Barsapara Cricket Stadium,  30 SEP 2023  2:00 PM IST  \n",
       "5                        Pingfeng Cricket Field,   3 OCT 2023  6:30 AM IST  \n",
       "6              Greenfield International Stadium,   3 OCT 2023  2:00 PM IST  \n",
       "7                        MA Chidambaram Stadium,   8 OCT 2023  2:00 PM IST  \n",
       "8                          Arun Jaitley Stadium,  11 OCT 2023  2:00 PM IST  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_BCCI=pd.DataFrame({\"Match_title\":Match_title,\"Series\":Series,\"Place\":Place,\"Date\":Date,\"Time\":Time})\n",
    "df_BCCI   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95abcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/You have to find following details: \n",
    "#A)Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices E) Share(18-19) F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a798de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8deffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the state wise GDP of India from statistics on automated chrome browser:\n",
    "driver.get(\"https://www.statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96c8b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the 'economy'\n",
    "economy=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "economy.click()\n",
    "\n",
    "# clicking the 'dropdown button'\n",
    "dropdown=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdb4a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDSP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank           State GDSP_19_20 GSDP_18_19 Share_18_19 GDP_billion\n",
       "0    1     Maharashtra          -  2,632,792      13.94%     399.921\n",
       "1    2      Tamil Nadu  1,845,853  1,630,208       8.63%     247.629\n",
       "2    3   Uttar Pradesh  1,687,818  1,584,764       8.39%     240.726\n",
       "3    4         Gujarat          -  1,502,899       7.96%     228.290\n",
       "4    5       Karnataka  1,631,977  1,493,127       7.91%     226.806\n",
       "5    6     West Bengal  1,253,832  1,089,898       5.77%     165.556\n",
       "6    7       Rajasthan  1,020,989    942,586       4.99%     143.179\n",
       "7    8  Andhra Pradesh    972,782    862,957       4.57%     131.083\n",
       "8    9       Telangana    969,604    861,031       4.56%     130.791\n",
       "9   10  Madhya Pradesh    906,672    809,592       4.29%     122.977"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clicking the 'statewise GDP of India'\n",
    "GDP_of_India=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "GDP_of_India.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Rank=[]\n",
    "State=[]\n",
    "GDSP_19_20=[]\n",
    "GSDP_18_19=[]\n",
    "Share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "# scraping rank\n",
    "rank = driver.find_elements(By.XPATH,'//td[@class=\"data1\"]')[:33]\n",
    "for i in rank:       \n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "                \n",
    "# scraping state\n",
    "state = driver.find_elements(By.XPATH,'//td[@class=\"name\"]')[:33]\n",
    "for i in state:       \n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "                \n",
    "# scraping GSDP at current price (19-20)\n",
    "GSDP = driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[:165]\n",
    "for i in GSDP:       \n",
    "    if i.text is None :\n",
    "        GDSP_19_20.append(\"--\") \n",
    "    else:\n",
    "        GDSP_19_20.append(i.text)\n",
    "                \n",
    "# scraping GSDP at current price (18-19)\n",
    "GSDP = driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]')[:33]\n",
    "for i in GSDP:       \n",
    "    if i.text is None :\n",
    "        GSDP_18_19.append(\"--\") \n",
    "    else:\n",
    "        GSDP_18_19.append(i.text)\n",
    "                \n",
    "# scraping Share(18-19)\n",
    "share = driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[:165]\n",
    "for i in share:       \n",
    "    if i.text is None :\n",
    "        Share_18_19.append(\"--\") \n",
    "    else:\n",
    "        Share_18_19.append(i.text)\n",
    "                \n",
    "# scraping GDP($ billion)\n",
    "GDP = driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[:165]\n",
    "for i in GDP:\n",
    "    if i.text is None :\n",
    "            GDP_billion.append(\"--\") \n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Rank\":Rank,\"State\":State,\"GDSP_19_20\":GDSP_19_20[::5],\"GSDP_18_19\":GSDP_18_19,\"Share_18_19\":Share_18_19[1::5],\"GDP_billion\":GDP_billion[2::5]})\n",
    "df.head(10)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c2173149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Scrape the details of trending repositories on Github.com. Url = https://github.com/You have to find the following details: \n",
    "#A) Repository title B) Repository description C) Contributors count D) Language used Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "50c68bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bb2afe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the github on automated chrome browser:\n",
    "driver.get(\"https://github.com/trending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "88f989c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opentofu /</td>\n",
       "      <td>OpenTofu lets you declaratively manage your cl...</td>\n",
       "      <td>8,488</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ProjectUnifree /</td>\n",
       "      <td>[SIGGRAPH Asia 2023] Rerender A Video: Zero-Sh...</td>\n",
       "      <td>239</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>williamyang1991 /</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>674</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PowerShell /</td>\n",
       "      <td>Clone a voice in 5 seconds to generate arbitra...</td>\n",
       "      <td>36</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CorentinJ /</td>\n",
       "      <td>Your self-hosted, globally interconnected micr...</td>\n",
       "      <td>1,661</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mastodon /</td>\n",
       "      <td>Code and models for NExT-GPT: Any-to-Any Multi...</td>\n",
       "      <td>86</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NExT-GPT /</td>\n",
       "      <td>The paper list of the 86-page paper \"The Rise ...</td>\n",
       "      <td>40,591</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WooooDyy /</td>\n",
       "      <td>Public repo for my latest and greatest cogniti...</td>\n",
       "      <td>7,514</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daveshap /</td>\n",
       "      <td>ðŸ¸ðŸ’¬ - a deep learning toolkit for Text-to-Speec...</td>\n",
       "      <td>45,551</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coqui-ai /</td>\n",
       "      <td>ðŸ”¥ ðŸ”¥ ðŸ”¥ Open Source JIRA, Linear and Height Alte...</td>\n",
       "      <td>8,060</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Repository_title                             Repository_description  \\\n",
       "0         opentofu /  OpenTofu lets you declaratively manage your cl...   \n",
       "1   ProjectUnifree /  [SIGGRAPH Asia 2023] Rerender A Video: Zero-Sh...   \n",
       "2  williamyang1991 /                       PowerShell for every system!   \n",
       "3       PowerShell /  Clone a voice in 5 seconds to generate arbitra...   \n",
       "4        CorentinJ /  Your self-hosted, globally interconnected micr...   \n",
       "5         mastodon /  Code and models for NExT-GPT: Any-to-Any Multi...   \n",
       "6         NExT-GPT /  The paper list of the 86-page paper \"The Rise ...   \n",
       "7         WooooDyy /  Public repo for my latest and greatest cogniti...   \n",
       "8         daveshap /  ðŸ¸ðŸ’¬ - a deep learning toolkit for Text-to-Speec...   \n",
       "9         coqui-ai /  ðŸ”¥ ðŸ”¥ ðŸ”¥ Open Source JIRA, Linear and Height Alte...   \n",
       "\n",
       "  Contributors_count     Language_used  \n",
       "0              8,488                Go  \n",
       "1                239            Python  \n",
       "2                674  Jupyter Notebook  \n",
       "3                 36                C#  \n",
       "4              1,661            Python  \n",
       "5                 86              Ruby  \n",
       "6             40,591            Python  \n",
       "7              7,514            Python  \n",
       "8             45,551        TypeScript  \n",
       "9              8,060        JavaScript  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list for scraping the data\n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "# scraping Repository_title\n",
    "repo_title = driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')[:22]\n",
    "for i in repo_title:       \n",
    "    if i.text is None :\n",
    "        Repository_title.append(\"--\") \n",
    "    else:\n",
    "        Repository_title.append(i.text)\n",
    "                        \n",
    "# scraping Repository_description\n",
    "repo_desc = driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')[:22]\n",
    "for i in repo_desc:       \n",
    "    if i.text is None :\n",
    "        Repository_description.append(\"--\") \n",
    "    else:\n",
    "        Repository_description.append(i.text)\n",
    "        \n",
    "# scraping Contibutors_count\n",
    "cont = driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"]')[:22]\n",
    "for i in cont:       \n",
    "    if i.text is None :\n",
    "        Contributors_count.append(\"--\") \n",
    "    else:\n",
    "        Contributors_count.append(i.text)\n",
    "            \n",
    "# scraping Language_used\n",
    "lang = driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')[:22]\n",
    "for i in lang:       \n",
    "    if i.text is None :\n",
    "        Language_used.append(\"--\") \n",
    "    else:\n",
    "        Language_used.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Repository_title\":Repository_title,\"Repository_description\":Repository_description,\"Contributors_count\":Contributors_count,\"Language_used\":Language_used})\n",
    "df.head(10)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "975b4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/You have to find the following details: \n",
    "#A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dbf1377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5e126f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the billboard page on automated chrome browser:\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a57a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the chart\n",
    "chart=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]\")\n",
    "chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f1cb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the view chart\n",
    "hot100=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a\")\n",
    "hot100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a54053bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vampire',\n",
       " 'Paint The Town Red',\n",
       " 'I Remember Everything',\n",
       " 'Fast Car',\n",
       " 'Cruel Summer',\n",
       " 'Last Night',\n",
       " 'Bad Idea Right?',\n",
       " 'Snooze',\n",
       " 'Fukumean',\n",
       " 'Dance The Night',\n",
       " 'Get Him Back!',\n",
       " 'Calm Down',\n",
       " 'All-American Bitch',\n",
       " 'Bongos',\n",
       " 'Barbie World',\n",
       " 'The Grudge',\n",
       " 'Flowers',\n",
       " 'All My Life',\n",
       " 'Making The Bed',\n",
       " 'Logical',\n",
       " 'Religiously',\n",
       " 'Rich Men North Of Richmond',\n",
       " 'Lacy',\n",
       " 'Ballad Of A Homeschooled Girl',\n",
       " 'Love Is Embarrassing',\n",
       " 'Used To Be Young',\n",
       " \"Thinkin' Bout Me\",\n",
       " 'Need A Favor',\n",
       " 'Kill Bill',\n",
       " \"Pretty Isn't Pretty\",\n",
       " 'Anti-Hero',\n",
       " 'What Was I Made For?',\n",
       " 'Peaches & Eggplants',\n",
       " 'Hey Driver',\n",
       " \"Creepin'\",\n",
       " 'Karma',\n",
       " 'Meltdown',\n",
       " 'Dial Drunk',\n",
       " 'Teenage Dream',\n",
       " 'Watermelon Moonshine',\n",
       " 'I Know ?',\n",
       " 'Qlona',\n",
       " 'Try That In A Small Town',\n",
       " 'Seven',\n",
       " 'Tourniquet',\n",
       " 'What It Is (Block Boy)',\n",
       " 'Single Soon',\n",
       " 'Daylight',\n",
       " 'Love You Anyway',\n",
       " 'Bury Me In Georgia',\n",
       " 'Slow Dancing',\n",
       " 'Spotless',\n",
       " 'Lady Gaga',\n",
       " 'Mi Ex Tenia Razon',\n",
       " 'East Side Of Sorrow',\n",
       " 'Save Me',\n",
       " 'LaLa',\n",
       " 'Good Good',\n",
       " 'In Your Love',\n",
       " 'Bipolar',\n",
       " 'White Horse',\n",
       " 'Last Time I Saw You',\n",
       " 'Telekinesis',\n",
       " 'FE!N',\n",
       " 'Popular',\n",
       " 'SkeeYee',\n",
       " 'Everything I Love',\n",
       " 'Que Onda',\n",
       " \"Angels Don't Always Have Wings\",\n",
       " 'Lose Control',\n",
       " 'Deli',\n",
       " 'Tulum',\n",
       " 'Truck Bed',\n",
       " 'Sabor Fresa',\n",
       " \"Fear And Friday's\",\n",
       " 'El Dorado',\n",
       " 'Johnny Dang',\n",
       " 'Oh U Went',\n",
       " 'Put It On Da Floor Again',\n",
       " 'Where She Goes',\n",
       " 'Ticking',\n",
       " \"Summertime's Close\",\n",
       " 'Dawns',\n",
       " 'Oklahoma Smoke Show',\n",
       " 'Call Your Friends',\n",
       " 'Overtime',\n",
       " 'Pretty Little Poison',\n",
       " 'Come See Me',\n",
       " 'El Amor de Su Vida',\n",
       " 'Holy Roller',\n",
       " 'Girl In Mine',\n",
       " 'Smaller Acts',\n",
       " 'Fight The Feeling',\n",
       " 'K-POP',\n",
       " 'Summer Too Hot',\n",
       " 'Lagunas',\n",
       " \"Sittin' On Top Of The World\",\n",
       " 'Rubicon',\n",
       " 'TQM',\n",
       " 'Amargura']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "# scraping Song nametitle-of-a-story\n",
    "song = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/h3')\n",
    "for i in song:       \n",
    "    if i.text is None :\n",
    "        Song_name.append(\"--\") \n",
    "    else:\n",
    "        Song_name.append(i.text)         \n",
    "Song_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b950cb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olivia Rodrigo',\n",
       " 'Doja Cat',\n",
       " 'Zach Bryan Featuring Kacey Musgraves',\n",
       " 'Luke Combs',\n",
       " 'Taylor Swift',\n",
       " 'Morgan Wallen',\n",
       " 'Olivia Rodrigo',\n",
       " 'SZA',\n",
       " 'Gunna',\n",
       " 'Dua Lipa',\n",
       " 'Olivia Rodrigo',\n",
       " 'Rema & Selena Gomez',\n",
       " 'Olivia Rodrigo',\n",
       " 'Cardi B & Megan Thee Stallion',\n",
       " 'Nicki Minaj & Ice Spice With Aqua',\n",
       " 'Olivia Rodrigo',\n",
       " 'Miley Cyrus',\n",
       " 'Lil Durk Featuring J. Cole',\n",
       " 'Olivia Rodrigo',\n",
       " 'Olivia Rodrigo',\n",
       " 'Bailey Zimmerman',\n",
       " 'Oliver Anthony Music',\n",
       " 'Olivia Rodrigo',\n",
       " 'Olivia Rodrigo',\n",
       " 'Olivia Rodrigo',\n",
       " 'Miley Cyrus',\n",
       " 'Morgan Wallen',\n",
       " 'Jelly Roll',\n",
       " 'SZA',\n",
       " 'Olivia Rodrigo',\n",
       " 'Taylor Swift',\n",
       " 'Billie Eilish',\n",
       " 'Young Nudy Featuring 21 Savage',\n",
       " 'Zach Bryan Featuring The War And Treaty',\n",
       " 'Metro Boomin, The Weeknd & 21 Savage',\n",
       " 'Taylor Swift Featuring Ice Spice',\n",
       " 'Travis Scott Featuring Drake',\n",
       " 'Noah Kahan With Post Malone',\n",
       " 'Olivia Rodrigo',\n",
       " 'Lainey Wilson',\n",
       " 'Travis Scott',\n",
       " 'Karol G & Peso Pluma',\n",
       " 'Jason Aldean',\n",
       " 'Jung Kook Featuring Latto',\n",
       " 'Zach Bryan',\n",
       " 'Doechii Featuring Kodak Black',\n",
       " 'Selena Gomez',\n",
       " 'David Kushner',\n",
       " 'Luke Combs',\n",
       " 'Kane Brown',\n",
       " 'V',\n",
       " 'Zach Bryan Featuring The Lumineers',\n",
       " 'Peso Pluma, Gabito Ballesteros & Junior H',\n",
       " 'Karol G',\n",
       " 'Zach Bryan',\n",
       " 'Jelly Roll With Lainey Wilson',\n",
       " 'Myke Towers',\n",
       " 'Usher, Summer Walker & 21 Savage',\n",
       " 'Tyler Childers',\n",
       " 'Peso Pluma x Jasiel Nunez x Junior H',\n",
       " 'Chris Stapleton',\n",
       " 'Nicki Minaj',\n",
       " 'Travis Scott Featuring SZA & Future',\n",
       " 'Travis Scott Featuring Playboi Carti',\n",
       " 'The Weeknd, Playboi Carti & Madonna',\n",
       " 'Sexyy Red',\n",
       " 'Morgan Wallen',\n",
       " 'Calle 24 x Chino Pacas x Fuerza Regida',\n",
       " 'Thomas Rhett',\n",
       " 'Teddy Swims',\n",
       " 'Ice Spice',\n",
       " 'Peso Pluma & Grupo Frontera',\n",
       " 'HARDY',\n",
       " 'Fuerza Regida',\n",
       " 'Zach Bryan',\n",
       " 'Zach Bryan',\n",
       " 'That Mexican OT, Paul Wall & DRODi',\n",
       " 'Young Thug Featuring Drake',\n",
       " 'Latto Featuring Cardi B',\n",
       " 'Bad Bunny',\n",
       " 'Zach Bryan',\n",
       " 'Zach Bryan',\n",
       " 'Zach Bryan Featuring Maggie Rogers',\n",
       " 'Zach Bryan',\n",
       " 'Rod Wave',\n",
       " 'Zach Bryan',\n",
       " 'Warren Zeiders',\n",
       " 'Rod Wave',\n",
       " 'Grupo Frontera & Grupo Firme',\n",
       " 'Zach Bryan Featuring Sierra Ferrell',\n",
       " 'Parmalee',\n",
       " 'Zach Bryan',\n",
       " 'Rod Wave',\n",
       " 'Travis Scott, Bad Bunny & The Weeknd',\n",
       " 'Chris Brown',\n",
       " 'Peso Pluma & Jasiel Nunez',\n",
       " 'Burna Boy',\n",
       " 'Peso Pluma',\n",
       " 'Fuerza Regida',\n",
       " 'Karol G']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Artist name\n",
    "Artist_name = []\n",
    "artist = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/span')\n",
    "for i in artist:       \n",
    "    if i.text is None :\n",
    "        Artist_name.append(\"--\") \n",
    "    else:\n",
    "        Artist_name.append(i.text) \n",
    "Artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c2e33a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '26',\n",
       " '7',\n",
       " '8',\n",
       " '6',\n",
       " '-',\n",
       " '10',\n",
       " '-',\n",
       " '-',\n",
       " '12',\n",
       " '-',\n",
       " '13',\n",
       " '14',\n",
       " '-',\n",
       " '-',\n",
       " '15',\n",
       " '11',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '16',\n",
       " '19',\n",
       " '18',\n",
       " '21',\n",
       " '-',\n",
       " '20',\n",
       " '22',\n",
       " '51',\n",
       " '17',\n",
       " '25',\n",
       " '24',\n",
       " '27',\n",
       " '28',\n",
       " '-',\n",
       " '33',\n",
       " '34',\n",
       " '31',\n",
       " '30',\n",
       " '37',\n",
       " '29',\n",
       " '41',\n",
       " '39',\n",
       " '42',\n",
       " '32',\n",
       " '36',\n",
       " '-',\n",
       " '35',\n",
       " '47',\n",
       " '43',\n",
       " '40',\n",
       " '79',\n",
       " '44',\n",
       " '58',\n",
       " '65',\n",
       " '-',\n",
       " '57',\n",
       " '23',\n",
       " '50',\n",
       " '54',\n",
       " '66',\n",
       " '67',\n",
       " '64',\n",
       " '61',\n",
       " '73',\n",
       " '81',\n",
       " '60',\n",
       " '71',\n",
       " '59',\n",
       " '70',\n",
       " '48',\n",
       " '49',\n",
       " '75',\n",
       " '76',\n",
       " '68',\n",
       " '72',\n",
       " '52',\n",
       " '53',\n",
       " '77',\n",
       " '80',\n",
       " '97',\n",
       " '55',\n",
       " '87',\n",
       " '56',\n",
       " '93',\n",
       " '69',\n",
       " '92',\n",
       " '63',\n",
       " '-',\n",
       " '74',\n",
       " '94',\n",
       " '-',\n",
       " '86',\n",
       " '95',\n",
       " '89',\n",
       " '91']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Last_week_rank =[]\n",
    "lw_rank = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[4]/span')\n",
    "for i in lw_rank:       \n",
    "    if i.text is None :\n",
    "        Last_week_rank.append(\"--\") \n",
    "    else:\n",
    "        Last_week_rank.append(i.text)  \n",
    "Last_week_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3609586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>Zach Bryan Featuring Kacey Musgraves</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td>-</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sittin' On Top Of The World</td>\n",
       "      <td>Burna Boy</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TQM</td>\n",
       "      <td>Fuerza Regida</td>\n",
       "      <td>89</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Amargura</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song_name                           Artist_name  \\\n",
       "0                       Vampire                        Olivia Rodrigo   \n",
       "1            Paint The Town Red                              Doja Cat   \n",
       "2         I Remember Everything  Zach Bryan Featuring Kacey Musgraves   \n",
       "3                      Fast Car                            Luke Combs   \n",
       "4                  Cruel Summer                          Taylor Swift   \n",
       "..                          ...                                   ...   \n",
       "95                      Lagunas             Peso Pluma & Jasiel Nunez   \n",
       "96  Sittin' On Top Of The World                             Burna Boy   \n",
       "97                      Rubicon                            Peso Pluma   \n",
       "98                          TQM                         Fuerza Regida   \n",
       "99                     Amargura                               Karol G   \n",
       "\n",
       "   Last_week_rank Peak_rank Weeks_on_board  \n",
       "0               9         1             11  \n",
       "1               1         1              6  \n",
       "2               2         1              3  \n",
       "3               3         2             25  \n",
       "4               4         3             19  \n",
       "..            ...       ...            ...  \n",
       "95              -        77              9  \n",
       "96             86        80              3  \n",
       "97             95        63             11  \n",
       "98             89        34             17  \n",
       "99             91        85              5  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Peak_rank = []\n",
    "Weeks_on_board = []\n",
    "peak = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[5]/span')\n",
    "\n",
    "for i in peak:       \n",
    "    if i.text is None :\n",
    "        Peak_rank.append(\"--\") \n",
    "    else:\n",
    "        Peak_rank.append(i.text)    \n",
    "\n",
    "# scraping Weeks_on_board\n",
    "on_board = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[6]/span')\n",
    "\n",
    "for i in on_board:       \n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\")\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Song_name\":Song_name,\"Artist_name\":Artist_name,\"Last_week_rank\":Last_week_rank,\"Peak_rank\":Peak_rank,\"Weeks_on_board\":Weeks_on_board})\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1e3dc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Scrape the details of Highest selling novels.https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "#compare A) Book name B) Author name C) Volumes sold D) Publisher E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5be7c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "32be61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the highest selling novel page from guradian.com on automated chrome browser:\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3e110319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#scraping Books Name\n",
    "book=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in book:\n",
    "    if i.text is None :\n",
    "        Book_name.append(\"--\") \n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "                \n",
    "# scraping Author name\n",
    "author=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in author:\n",
    "    if i.text is None :\n",
    "        Author_name.append(\"--\") \n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "\n",
    "# scraping Volumes Sold\n",
    "volume=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in volume:\n",
    "    if i.text is None :\n",
    "        Volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "                \n",
    "# scraping Publisher\n",
    "publisher=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in publisher:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"--\") \n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "               \n",
    "# scraping Genre\n",
    "genre = driver.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\")\n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Book_name\":Book_name[1::5],\"Author_name\":Author_name[2::5],\"Volumes_sold\":Volumes_sold[3::5],\"Publisher\":Publisher[4::5],\"Genre\":Genre})\n",
    "df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c0663811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details: \n",
    "#A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cbcf2e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7c390dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening theimdb page on automated chrome browser:\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "377c0579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,205,367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016â€“2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,276,697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010â€“2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,046,380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>307,536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005â€“ )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>266,272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011â€“2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016â€“2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010â€“2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017â€“2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014â€“2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013â€“2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017â€“2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005â€“ )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015â€“2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  2,205,367  \n",
       "1    51 min     8.7  1,276,697  \n",
       "2    44 min     8.1  1,046,380  \n",
       "3    60 min     7.5    307,536  \n",
       "4    43 min     7.6    266,625  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,759  \n",
       "96   50 min     7.8     64,815  \n",
       "97   42 min     8.1    211,134  \n",
       "98   45 min       7     43,926  \n",
       "99  572 min     8.6    266,272  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty lists for scraping data\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "# scraping top Movies name\n",
    "name = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a')\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "#scraping year span       \n",
    "year = driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year:       \n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text) \n",
    "        \n",
    "#scraping genre       \n",
    "gen = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in gen :       \n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "        \n",
    "#scraping run time\n",
    "time = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in time:       \n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)\n",
    "\n",
    "rate = driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]')\n",
    "for i in rate:       \n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text)\n",
    "\n",
    "#scraping votes\n",
    "vote = driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in vote:       \n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        Votes.append(i.text)\n",
    "\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name,\"Year_span\":Year_span,\"Genre\":Genre,\"Run_time\":Run_time,\"Ratings\":Ratings,\"Votes\":Votes})\n",
    "df        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "49532588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/You have to find the following details: \n",
    "#A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0eae8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "# Opening the UCI machine learning repository page on automated chrome browser:\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "# clicking the 'View all dataset'\n",
    "view_dataset=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/header/nav/ul/li[1]/a\")\n",
    "view_dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e935a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click in expand all\n",
    "svg =driver.find_element(By.XPATH,'//div[@class=\"flex flex-wrap items-center gap-4\"]')\n",
    "svg.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cb75ac0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_features</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Features</td>\n",
       "      <td>4/27/1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset_name     Data_type            Task  \\\n",
       "0                                  Iris       Tabular  Classification   \n",
       "1                         Heart Disease  Multivariate  Classification   \n",
       "2                                 Adult  Multivariate  Classification   \n",
       "3                      Dry Bean Dataset  Multivariate  Classification   \n",
       "4                              Diabetes                                 \n",
       "5                                  Wine       Tabular  Classification   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)  Multivariate  Classification   \n",
       "7                        Car Evaluation  Multivariate  Classification   \n",
       "8            Rice (Cammeo and Osmancik)  Multivariate  Classification   \n",
       "9                              Mushroom  Multivariate  Classification   \n",
       "\n",
       "               Attribute_type   No_of_instances No_of_features       Year  \n",
       "0                        Real     150 Instances     4 Features   7/1/1988  \n",
       "1  Categorical, Integer, Real     303 Instances    13 Features   7/1/1988  \n",
       "2        Categorical, Integer  48.84K Instances    14 Features   5/1/1996  \n",
       "3               Integer, Real  13.61K Instances    16 Features  9/14/2020  \n",
       "4        Categorical, Integer                      20 Features        N/A  \n",
       "5               Integer, Real     178 Instances    13 Features   7/1/1991  \n",
       "6                        Real     569 Instances    30 Features  11/1/1995  \n",
       "7                 Categorical   1.73K Instances     6 Features   6/1/1997  \n",
       "8                        Real   3.81K Instances     8 Features  10/6/2019  \n",
       "9                 Categorical   8.12K Instances    22 Features  4/27/1987  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Dataset_name\n",
    "Dataset_name = []\n",
    "dataset = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in dataset:       \n",
    "    if i.text is None :\n",
    "        Dataset_name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_name.append(i.text)\n",
    "#Dataset_name\n",
    "Data_type = []\n",
    "datatype = driver.find_elements(By.XPATH,'//div[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[2]/span')\n",
    "for i in datatype:       \n",
    "    if i.text is None :\n",
    "        Data_type.append(\"--\") \n",
    "    else:\n",
    "        Data_type.append(i.text)\n",
    "#Data_type\n",
    "Task=[]\n",
    "# scraping Task\n",
    "#task = driver.find_elements(By.XPATH,'//span[@class=\"truncate\"]')\n",
    "task = driver.find_elements(By.XPATH,'//div[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[1]/span')\n",
    "\n",
    "for i in task:       \n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "#Task\n",
    "Attribute_type=[]\n",
    "\n",
    "attribute_type = driver.find_elements(By.XPATH,'//div[@class=\"flex flex-col gap-1\"]/div/div[2]/div/table/tbody/tr/td[2]')\n",
    "\n",
    "for i in attribute_type:       \n",
    "    if i.text is None :\n",
    "        Attribute_type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_type.append(i.text)\n",
    "#Attribute_type \n",
    "# scraping No_of_instances\n",
    "No_of_instances=[]\n",
    "instances = driver.find_elements(By.XPATH,'//div[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[3]/span')\n",
    "for i in instances:       \n",
    "    if i.text is None :\n",
    "        No_of_instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_instances.append(i.text)\n",
    "#No_of_instances\n",
    "# scraping No_of_attribute\n",
    "No_of_attribute= []\n",
    "attribute = driver.find_elements(By.XPATH,'//div[@class=\"flex flex-col gap-1\"]/div/div/div[2]/div/div[4]/span')\n",
    "for i in attribute:\n",
    "    if i.text is None :\n",
    "        No_of_attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_attribute.append(i.text)\n",
    "#No_of_attribute\n",
    "Year = []\n",
    "year = driver.find_elements(By.XPATH,'//div[@class=\"flex flex-col gap-1\"]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "for i in year:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\")\n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "#Year\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Dataset_name\":Dataset_name,\n",
    "                 \"Data_type\":Data_type,\n",
    "                 \"Task\":Task,\n",
    "                 \"Attribute_type\":Attribute_type,\n",
    "                 \"No_of_instances\":No_of_instances,\n",
    "                 \"No_of_features\":No_of_attribute,\n",
    "                 \"Year\":Year})\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d41d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
